{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "17812e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob, os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, activations, optimizers, losses, metrics, initializers\n",
    "from tensorflow.keras.preprocessing import image, image_dataset_from_directory\n",
    "from tensorflow.keras.applications import MobileNetV3Small, MobileNet, InceptionV3\n",
    "from tensorflow.keras.applications.mobilenet_v3 import preprocess_input, decode_predictions\n",
    "\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5a932f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = 'Dataset_BUSI_with_GT/'\n",
    "IMAGE_SHAPE = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "aca32acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create prepare_image method\n",
    "# used to preprocess the image for efficientNet model\n",
    "def prepare_image(file):\n",
    "    img = image.load_img(file, target_size=IMAGE_SHAPE)\n",
    "    img_array = image.img_to_array(img)\n",
    "    return tf.keras.applications.efficientnet.preprocess_input (img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "711c33ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1578, 1578)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directories = os.listdir(dir_path) # read the folders\n",
    "\n",
    "files = [] # save all images for each folder\n",
    "labels = [] # set for each image the name of it\n",
    "\n",
    "# read files for each directory\n",
    "for folder in directories:\n",
    "    \n",
    "    fileList = glob.glob(dir_path + '/'+ folder + '/*')\n",
    "    labels.extend([folder for l in fileList])\n",
    "    files.extend(fileList)\n",
    "    \n",
    "len(files), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "33871ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(780, 780)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create two lists to hold only non-mask images and label for each one\n",
    "selected_files = []\n",
    "selected_labels = []\n",
    "\n",
    "for file, label in zip(files, labels):\n",
    "    if 'mask' not in file:\n",
    "        selected_files.append(file)\n",
    "        selected_labels.append(label)\n",
    "\n",
    "    \n",
    "len(selected_files), len(selected_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "69573bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the image...\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "# the dictionary holds list of images and for each one has its target/label\n",
    "images = {\n",
    "    'image': [], \n",
    "    'target': []\n",
    "}\n",
    "\n",
    "print('Preparing the image...')\n",
    "\n",
    "for i, (file, label) in enumerate(zip(selected_files, selected_labels)):\n",
    "    images['image'].append(prepare_image(file))\n",
    "    images['target'].append(label)\n",
    "\n",
    "print('Finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "521c5812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the target classes are: ['benign' 'malignant' 'normal']\n"
     ]
    }
   ],
   "source": [
    "# convert lists to arrays \n",
    "images['image'] = np.array(images['image'])\n",
    "images['target'] = np.array(images['target'])\n",
    "\n",
    "# encode the target\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "images['target'] = le.fit_transform(images['target'])\n",
    "\n",
    "classes = le.classes_ # get the classes for each target\n",
    "print(f'the target classes are: {classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "48b6a490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((702, 224, 224, 3), (78, 224, 224, 3), (702,), (78,))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(images['image'], images['target'], test_size=.10)\n",
    "\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "98c84517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 20s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "base_model = VGG16(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(*IMAGE_SHAPE, 3),\n",
    "    classes=3)\n",
    "\n",
    "# Freeze the base_model\n",
    "base_model.trainable = False\n",
    "\n",
    "# append my own layers on the top of the model for Transfer Learning\n",
    "x = base_model.output\n",
    "\n",
    "# 1st conv block\n",
    "x = layers.Conv2D(256, 3, padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.GlobalAveragePooling2D(keepdims = True)(x)\n",
    "\n",
    "# 2nd conv block\n",
    "x = layers.Conv2D(128, 3, padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.GlobalAveragePooling2D(keepdims = True)(x)\n",
    "\n",
    "# 1st FC layer\n",
    "x = layers.Flatten()(x) \n",
    "x = layers.Dense(64)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "\n",
    "# 2nd FC layer\n",
    "x = layers.Dense(32, activation = 'relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.Dropout(.2)(x)\n",
    "\n",
    "x = layers.Dense(3, 'softmax')(x)\n",
    "\n",
    "incept_model = keras.models.Model(inputs = base_model.input, outputs = x)\n",
    "\n",
    "# compile the model\n",
    "incept_model.compile(optimizer=optimizers.RMSprop(.001), loss = losses.sparse_categorical_crossentropy, metrics= [metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "# incept_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef986a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "22/22 [==============================] - 112s 5s/step - loss: 1.0104 - sparse_categorical_accuracy: 0.5470 - val_loss: 0.9435 - val_sparse_categorical_accuracy: 0.5385\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 111s 5s/step - loss: 0.6437 - sparse_categorical_accuracy: 0.7464 - val_loss: 1.0080 - val_sparse_categorical_accuracy: 0.5256\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 112s 5s/step - loss: 0.4963 - sparse_categorical_accuracy: 0.8120 - val_loss: 0.9942 - val_sparse_categorical_accuracy: 0.5256\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 113s 5s/step - loss: 0.3856 - sparse_categorical_accuracy: 0.8789 - val_loss: 0.9065 - val_sparse_categorical_accuracy: 0.5513\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 111s 5s/step - loss: 0.3220 - sparse_categorical_accuracy: 0.8889 - val_loss: 0.8801 - val_sparse_categorical_accuracy: 0.6026\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 116s 5s/step - loss: 0.2518 - sparse_categorical_accuracy: 0.9231 - val_loss: 0.8221 - val_sparse_categorical_accuracy: 0.5513\n",
      "Epoch 7/100\n",
      " 9/22 [===========>..................] - ETA: 59s - loss: 0.2225 - sparse_categorical_accuracy: 0.9062 "
     ]
    }
   ],
   "source": [
    "earlyStop = keras.callbacks.EarlyStopping(patience=60) \n",
    "best_model = keras.callbacks.ModelCheckpoint(filepath='best_model.h5', save_best_only=True) \n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    history = incept_model.fit(x_train, y_train, batch_size=32, epochs=100, validation_data=(x_test, y_test), callbacks=[earlyStop, best_model]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd671c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = history.history\n",
    "\n",
    "plt.plot(hist['loss'], label=  'loss')\n",
    "plt.plot(hist['val_loss'], label = 'val_loss')\n",
    "plt.plot(hist['sparse_categorical_accuracy'], label='accuracy')\n",
    "plt.plot(hist['val_sparse_categorical_accuracy'], label='val_accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c73851",
   "metadata": {},
   "outputs": [],
   "source": [
    "incept_model.evaluate(x=x_test, y = y_test, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b205c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open train the last 100 layers\n",
    "for layer in incept_model.layers[720:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "# compile the model with new optimizer and lr=.0001\n",
    "incept_model.compile(optimizer=optimizers.RMSprop(.0001), loss = losses.sparse_categorical_crossentropy, metrics=[metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "# incept_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbd6759",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "earlyStop = keras.callbacks.EarlyStopping(patience=60) \n",
    "best_model = keras.callbacks.ModelCheckpoint(filepath='best_model_2.h5', save_best_only=True) \n",
    "\n",
    "# load the best weights\n",
    "# incept_model.set_weights(best_weights)\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    history = incept_model.fit(x_train, y_train, batch_size=32, epochs=100, validation_data=(x_test, y_test), callbacks=[earlyStop, best_model]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a64072",
   "metadata": {},
   "outputs": [],
   "source": [
    "incept_model.evaluate(x=x_test, y = y_test, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af193cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to predict the model and visualize the orignal image with title of true and pred values\n",
    "def predict_image(img_path, label):\n",
    "    img1 = prepare_image(img_path) # preprocess the image\n",
    "    res = incept_model.predict(np.expand_dims(img1, axis = 0)) # predict the image\n",
    "    pred = classes[np.argmax(res)]\n",
    "\n",
    "    # Visualize the image\n",
    "    img = image.load_img(img_path)\n",
    "    plt.imshow(np.array(img))\n",
    "    plt.title(f'True: {label}\\nPredicted: {pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9867571",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_image(dir_path + 'benign/benign (10).png', 'benign')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2623ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_image(dir_path + 'benign/benign (85).png', 'benign')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bef4144",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_image(dir_path + 'malignant/malignant (10).png', 'malignant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976654a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_image(dir_path + 'normal/normal (10).png', 'normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "668d781f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "incept_model.evaluate(np.array(x_test),np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3aa02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = []\n",
    "for item in incept_model.predict(x_test):\n",
    "    predicted.append(np.argmax(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c736ddc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7484f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in predicted:\n",
    "    print(item,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
